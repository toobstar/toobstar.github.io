+++
title = 'Emerging patterns in GenAI Risk Control'
date = 2025-04-02T13:04:53+11:00
draft = true
tags = ['Risk', 'CIO', 'AI', 'GenAI']
revision = 1
+++


![Improving Gemini AI](https://toobstar.github.io/images/caveman_computer.jpg)

## Generative AI: Slow, then fast, then *really* fast

Without providing a deep overview of AI its history has been surprising long.  With early research and commercialisation happening alongside the establishment of computer science even from the 1950s and the likes of Alan Turing. The work back then focussed on rule-based systems and provided basic probabilistic models that could generate simple text.

Through the 1990s and early 2000s neural networks and deep learning approaches developed to provide more practical commercial applications, but it will still at the fringe of engineering practice.  It has been in the last 10 years that the tranformer revolution and Generative Adversarial Networks (GANs) enabled AI to create realistic images and videos that we saw the use of AI become more central to engineering R&D efforts.  

And since 2020 with the widespread release of large scale language models (LLMs) based on the transformer architecture with the likes of GPT, DALL-E and Stable Diffusion we have seen the use of these become mainstream and the attention for all forward looking businesses to be focussed on GenAI as a potential approach to rapidly improve product and service outcomes. 

## Risk Overview

There are many obvious potential issues that jump to mind with GenAI that include:

- data loss through the use of chat-interactions in an uncontrolled context
- the output including hallucinations or factual errors that are undetected 
- privacy and copyright concerns with source data 